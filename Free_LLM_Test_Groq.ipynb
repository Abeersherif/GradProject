{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üÜì FREE LLM Test with Groq (No Credit Card Needed!)\n",
                "\n",
                "**Groq is 100% FREE and works exactly like DeepSeek!**\n",
                "\n",
                "- ‚úÖ No credit card required\n",
                "- ‚úÖ Very fast inference\n",
                "- ‚úÖ Good quality (Llama 3.1 70B)\n",
                "- ‚úÖ Same LangChain interface\n",
                "\n",
                "**Get API Key**: https://console.groq.com (free signup)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Step 1: Install Groq"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q langchain-groq\n",
                "print(\"‚úÖ Groq installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîë Step 2: Set API Key\n",
                "\n",
                "Get your FREE API key from: https://console.groq.com/keys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Replace with your Groq API key (free from https://console.groq.com)\n",
                "GROQ_API_KEY = \"your-groq-api-key-here\"\n",
                "\n",
                "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
                "\n",
                "if GROQ_API_KEY == \"your-groq-api-key-here\":\n",
                "    print(\"‚ö†Ô∏è  Please get your FREE API key from: https://console.groq.com/keys\")\n",
                "else:\n",
                "    print(f\"‚úÖ API key set! (starts with: {GROQ_API_KEY[:10]}...)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Step 3: Initialize Groq"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_groq import ChatGroq\n",
                "\n",
                "llm = ChatGroq(\n",
                "    model=\"llama-3.1-70b-versatile\",  # Free, powerful model\n",
                "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
                "    temperature=0.3\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Groq initialized!\")\n",
                "print(\"   Model: llama-3.1-70b-versatile\")\n",
                "print(\"   Cost: FREE!\")\n",
                "print(\"   Speed: Very Fast!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ Step 4: Test Basic Chat"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Testing Groq...\\n\")\n",
                "\n",
                "response = llm.invoke(\"Hello! Can you introduce yourself?\")\n",
                "print(\"Response:\")\n",
                "print(response.content)\n",
                "print(\"\\n‚úÖ Groq works perfectly!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üè• Step 5: Test Medical Question"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Testing medical knowledge...\\n\")\n",
                "\n",
                "response = llm.invoke(\"What are the main symptoms of diabetes? List 5 key symptoms.\")\n",
                "print(\"Response:\")\n",
                "print(response.content)\n",
                "print(\"\\n‚úÖ Medical knowledge test passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Step 6: Test JSON Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "prompt = \"\"\"Extract symptoms and return ONLY valid JSON:\n",
                "{\n",
                "  \"symptoms\": [\"list\"],\n",
                "  \"severity\": \"mild/moderate/severe\"\n",
                "}\n",
                "\n",
                "Message: \"I have chest pain for 3 days, it's moderate.\"\n",
                "\"\"\"\n",
                "\n",
                "response = llm.invoke(prompt)\n",
                "print(\"Raw response:\")\n",
                "print(response.content)\n",
                "\n",
                "# Parse JSON\n",
                "try:\n",
                "    content = response.content.strip()\n",
                "    if content.startswith(\"```json\"):\n",
                "        content = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
                "    \n",
                "    parsed = json.loads(content)\n",
                "    print(\"\\n‚úÖ JSON parsing successful!\")\n",
                "    print(json.dumps(parsed, indent=2))\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ö†Ô∏è  JSON parsing issue: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Step 7: Test Agent-Style Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TestAgent:\n",
                "    def __init__(self, llm):\n",
                "        self.llm = llm\n",
                "    \n",
                "    def classify_condition(self, symptoms):\n",
                "        prompt = f\"\"\"Classify into ONE category:\n",
                "diabetes, hypertension, heart_disease, copd, unknown\n",
                "\n",
                "Return ONLY the category name.\n",
                "\n",
                "Symptoms: {symptoms}\n",
                "\"\"\"\n",
                "        response = self.llm.invoke(prompt)\n",
                "        return response.content.strip().lower()\n",
                "\n",
                "# Test\n",
                "agent = TestAgent(llm)\n",
                "result = agent.classify_condition(\"high blood sugar, increased thirst, fatigue\")\n",
                "print(f\"Classified as: {result}\")\n",
                "print(\"\\n‚úÖ Agent-style usage works!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÖ Final Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"üéâ GROQ IS READY FOR YOUR AGENTS!\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\n‚úÖ All tests passed!\")\n",
                "print(\"‚úÖ 100% FREE (no credit card needed)\")\n",
                "print(\"‚úÖ Very fast inference\")\n",
                "print(\"‚úÖ Works exactly like DeepSeek\")\n",
                "print(\"\\nüìã To use in your MedTwin agents:\")\n",
                "print(\"\"\"\\n# Replace your LLM initialization with:\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(\n    model=\"llama-3.1-70b-versatile\",\n    api_key=os.environ[\"GROQ_API_KEY\"],\n    temperature=0.3\n)\n\n# Your agents work without any other changes!\n\"\"\")\n",
                "print(\"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}