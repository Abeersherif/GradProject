{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "691f134f",
      "metadata": {
        "id": "691f134f"
      },
      "source": [
        "# MedTwin - 2-Agent Medical Assistant System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bcb381eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb381eb",
        "outputId": "3837489f-44f3-4e90-87cb-7312d9b3a596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok --quiet\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"35byMfscC6rxe2Ey767RO45ryEC_4QjGJC4BPYVzUQBJBksF\")  # paste your token here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "997bf2bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "997bf2bf",
        "outputId": "cfe6c016-8b49-4f3c-dbd6-24f2c379dce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no old streamlit\n"
          ]
        }
      ],
      "source": [
        "# Kill any old streamlit processes (optional but safe)\n",
        "!pkill streamlit || echo \"no old streamlit\"\n",
        "\n",
        "# Start your app\n",
        "!streamlit run app.py --server.port 8501 >/dev/null 2>&1 &\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f8d9b9",
      "metadata": {
        "id": "51f8d9b9"
      },
      "source": [
        "## Install Ollama + LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a0bfe47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0bfe47",
        "outputId": "c63fcf01-c51c-4015-b905-a9b0ef77158c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Ollama and LangChain...\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h>>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "\n",
            "✓ All packages installed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing Ollama and LangChain...\\n\")\n",
        "\n",
        "!pip install -q colab-xterm\n",
        "!pip install -q langchain==0.3.7\n",
        "!pip install -q langchain-community==0.3.7\n",
        "!pip install -q langchain-ollama==0.2.0\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "print(\"\\n✓ All packages installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2431ff44",
      "metadata": {
        "id": "2431ff44"
      },
      "source": [
        "## Start Ollama Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a771c31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a771c31",
        "outputId": "01bdc369-b060-41f3-90fe-cf9028f7ccd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Ollama server started!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "import re\n",
        "from typing import Dict\n",
        "\n",
        "# ---------- Root / substring helper ----------\n",
        "def contains_root(text: str, roots) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if any root/keyword appears inside the text (case-insensitive).\n",
        "    Example: root 'diabet' will match 'diabetes' and 'diabetic'.\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    return any(root in text_lower for root in roots)\n",
        "\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "time.sleep(5)\n",
        "print(\"✓ Ollama server started!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf255154",
      "metadata": {
        "id": "bf255154"
      },
      "source": [
        "## Download AI Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26a05d67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a05d67",
        "outputId": "22a75a55-9116-4a47-ed42-f3c86d30d13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading Llama 3.2 (3-5 minutes first time)...\n",
            "\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\n",
            "✓ Model ready!\n"
          ]
        }
      ],
      "source": [
        "print(\" Downloading Llama 3.2 (3-5 minutes first time)...\\n\")\n",
        "!ollama pull llama3.2:3b\n",
        "print(\"\\n✓ Model ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a56e7cef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a56e7cef",
        "outputId": "f6ba6880-a86b-4fc4-af03-b3b54ae3032b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ FREE Llama 3.2 initialized!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "import re\n",
        "from typing import Dict, List\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(model=\"llama3.2:3b\", temperature=0.3)\n",
        "print(\"✓ FREE Llama 3.2 initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe039ce",
      "metadata": {
        "id": "ebe039ce"
      },
      "source": [
        "## IMPROVED Medical Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e80a05ab",
      "metadata": {
        "id": "e80a05ab"
      },
      "outputs": [],
      "source": [
        "MEDICAL_QUESTIONS = {\n",
        "    \"diabetes\": [\n",
        "        \"What's your fasting blood sugar level?\",\n",
        "        \"Have you noticed increased thirst or urination?\",\n",
        "        \"Any recent fatigue or blurred vision?\"\n",
        "    ],\n",
        "    \"hypertension\": [\n",
        "        \"What's your blood pressure reading?\",\n",
        "        \"Any headaches, dizziness, or chest discomfort?\",\n",
        "        \"Are you taking your hypertension medications?\"\n",
        "    ],\n",
        "\n",
        "    \"heart_disease\": [\n",
        "    \"Are you having any chest pain, tightness, or pressure right now?\",\n",
        "    \"Does any chest discomfort get worse when you walk, climb stairs, or exercise?\",\n",
        "    \"Do you feel short of breath during simple activities like walking or talking?\",\n",
        "    \"Have you noticed your heart beating fast, slow, or irregularly?\",\n",
        "    \"Do your legs, feet, or ankles swell by the end of the day?\",\n",
        "    \"Do your symptoms improve when you rest?\"\n",
        "],\n",
        "\n",
        "    \"copd\": [\n",
        "        \"How's your breathing today (1-10)?\",\n",
        "        \"Are you coughing or producing mucus?\",\n",
        "        \"Used your inhaler/bronchodilator recently?\",\n",
        "        \"Any chest tightness or wheezing?\",\n",
        "        \"Exposure to smoke, dust, or pollution today?\"\n",
        "    ],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f424b32c",
      "metadata": {
        "id": "f424b32c"
      },
      "source": [
        "## Agent 1 : IMPROVED Q&A Agent with Smart Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d4db3c9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4db3c9e",
        "outputId": "03416097-5ec7-424c-d460-ea2e7e01fa67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ SymptomQAAgent (Q&A with heart/COPD disambiguation) is loaded!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Helper functions\n",
        "# -------------------------------------------------------------------\n",
        "def contains_root(text: str, roots: List[str]) -> bool:\n",
        "    for r in roots:\n",
        "        if r in text:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def parse_llm_output(llm_response: str) -> Dict[str, Dict[str, Any]]:\n",
        "    try:\n",
        "        data = json.loads(llm_response)\n",
        "        return data if isinstance(data, dict) else {}\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Q&A-style agent with disambiguation and follow-up questions\n",
        "# -------------------------------------------------------------------\n",
        "class SymptomQAAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.full_conversation: List[str] = []\n",
        "        self.extracted_info: Dict[str, Any] = {}\n",
        "        self.current_question_index: int = 0\n",
        "        self.condition_type: str | None = None\n",
        "        self.answers: Dict[str, str] = {}\n",
        "        self.interview_complete: bool = False\n",
        "        self.red_flag_detected: bool = False\n",
        "\n",
        "        # heart vs COPD disambiguation state\n",
        "        self.awaiting_disambiguation: bool = False\n",
        "        self.possible_conditions: List[str] = []\n",
        "\n",
        "    # ------------------------------\n",
        "    # RULE-BASED EXTRACTION\n",
        "    # ------------------------------\n",
        "    def rule_based_extract(self, text: str):\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Timing\n",
        "        if re.search(r\"\\bfor (\\d+) (day|week|hour)s?\\b\", text_lower):\n",
        "            self.extracted_info[\"timing\"] = text\n",
        "\n",
        "        if any(p in text_lower for p in [\n",
        "            \"days ago\", \"day ago\", \"weeks ago\", \"week ago\",\n",
        "            \"last night\", \"yesterday\", \"this morning\", \"hours ago\", \"since\"\n",
        "        ]):\n",
        "            self.extracted_info[\"timing\"] = text\n",
        "\n",
        "        # Severity\n",
        "        if re.search(r'(\\d{1,2})\\s*/\\s*10', text_lower) or \\\n",
        "           re.search(r'\\b(mild|moderate|severe|unbearable)\\b', text_lower):\n",
        "            self.extracted_info[\"severity\"] = text\n",
        "\n",
        "        # Glucose\n",
        "        if re.search(r'\\bglucose\\b|\\bblood sugar\\b|\\bmg/dl\\b|\\bmmol\\b', text_lower):\n",
        "            self.extracted_info[\"glucose\"] = text\n",
        "\n",
        "        # Blood pressure\n",
        "        if re.search(r'\\b(bp|blood pressure)\\b|\\bmmhg\\b|\\d+/\\d+', text_lower):\n",
        "            self.extracted_info[\"blood_pressure\"] = text\n",
        "\n",
        "        # Medication\n",
        "        if re.search(r'\\b(medication|meds|pills|tablets|taking|took|missed|forgot)\\b', text_lower):\n",
        "            self.extracted_info[\"medication\"] = text\n",
        "\n",
        "        # Breathing\n",
        "        if any(k in text_lower for k in [\n",
        "            \"shortness of breath\", \"can't breathe\", \"cannot breathe\", \"struggling to breathe\",\n",
        "            \"difficulty breathing\", \"hard to breathe\", \"breathless\", \"dyspnea\"\n",
        "        ]) or re.search(r'\\bbreath(ing)?\\b', text_lower):\n",
        "            self.extracted_info[\"breathing_status\"] = text\n",
        "\n",
        "        # Cough / mucus\n",
        "        if re.search(r'\\b(cough|phlegm|mucus|sputum)\\b', text_lower):\n",
        "            self.extracted_info[\"cough_mucus\"] = text\n",
        "\n",
        "        # Respiratory triggers\n",
        "        if re.search(r'\\b(smok(e|ing)?|dust|pollut(ed|ion)?|fumes?|cigarette)\\b', text_lower):\n",
        "            self.extracted_info[\"resp_triggers\"] = text\n",
        "\n",
        "        # Red flags\n",
        "        if any(r in text_lower for r in [\n",
        "            \"can't breathe\", \"cannot breathe\", \"struggling to breathe\",\n",
        "            \"severe chest pain\", \"crushing chest pain\",\n",
        "            \"blue lips\", \"blue face\", \"passed out\", \"fainted\"\n",
        "        ]):\n",
        "            self.extracted_info[\"red_flag\"] = text\n",
        "            self.red_flag_detected = True\n",
        "\n",
        "    # ------------------------------\n",
        "    # LLM SYNONYM / INTENT EXTRACTION\n",
        "    # ------------------------------\n",
        "    def llm_synonym_extract(self, text: str):\n",
        "        prompt = (\n",
        "            \"Extract all symptoms, medical concepts, and possible intent from this message.\\n\"\n",
        "            \"Return JSON ONLY with this structure:\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"symptom1\\\": {\\n\"\n",
        "            \"    \\\"Canonical\\\": \\\"...\\\",\\n\"\n",
        "            \"    \\\"Original\\\": \\\"...\\\",\\n\"\n",
        "            \"    \\\"Corrected\\\": \\\"...\\\",\\n\"\n",
        "            \"    \\\"Synonyms\\\": [\\\"...\\\"],\\n\"\n",
        "            \"    \\\"Intent\\\": \\\"...\\\"\\n\"\n",
        "            \"  }\\n\"\n",
        "            \"}\\n\"\n",
        "            f\"Message: \\\"{text}\\\"\"\n",
        "        )\n",
        "        raw = self.llm.invoke(prompt).content.strip()\n",
        "        llm_data = parse_llm_output(raw)\n",
        "\n",
        "        for key, data in llm_data.items():\n",
        "            if isinstance(data, dict):\n",
        "                self.extracted_info[key] = {\n",
        "                    \"canonical\": data.get(\"Canonical\", \"\"),\n",
        "                    \"original\": data.get(\"Original\", \"\"),\n",
        "                    \"corrected\": data.get(\"Corrected\", \"\"),\n",
        "                    \"synonyms\": data.get(\"Synonyms\", []),\n",
        "                    \"intent\": data.get(\"Intent\", \"\")\n",
        "                }\n",
        "\n",
        "    def extract_info_from_text(self, text: str):\n",
        "        self.rule_based_extract(text)\n",
        "        self.llm_synonym_extract(text)\n",
        "\n",
        "    # ------------------------------\n",
        "    # LLM CONDITION GUESS (fallback)\n",
        "    # ------------------------------\n",
        "    def llm_condition_guess(self, text: str) -> str | None:\n",
        "        prompt = (\n",
        "            \"Classify the main condition in this message into exactly ONE of:\\n\"\n",
        "            \"diabetes, hypertension, heart_disease, copd, none.\\n\"\n",
        "            \"Return ONLY JSON: {\\\"condition\\\": \\\"...\\\", \\\"reason\\\": \\\"...\\\"}\\n\\n\"\n",
        "            f\"Message: \\\"{text}\\\"\"\n",
        "        )\n",
        "        raw = self.llm.invoke(prompt).content.strip()\n",
        "\n",
        "        try:\n",
        "            data = json.loads(raw)\n",
        "            cond = data.get(\"condition\", \"none\")\n",
        "            allowed = {\"diabetes\", \"hypertension\", \"heart_disease\", \"copd\"}\n",
        "            return cond if cond in allowed else None\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    # ------------------------------\n",
        "    # CONDITION IDENTIFICATION\n",
        "    # ------------------------------\n",
        "    def identify_condition(self, patient_input: str) -> str | None:\n",
        "        patient_lower = patient_input.lower()\n",
        "\n",
        "        synonym_parts: List[str] = []\n",
        "        for key, value in self.extracted_info.items():\n",
        "            if isinstance(value, dict):\n",
        "                synonym_parts.append(value.get(\"canonical\", \"\"))\n",
        "                synonym_parts.append(value.get(\"corrected\", \"\"))\n",
        "                synonym_parts.append(value.get(\"intent\", \"\"))\n",
        "                syns = value.get(\"synonyms\", [])\n",
        "                if isinstance(syns, list):\n",
        "                    synonym_parts.extend(syns)\n",
        "                else:\n",
        "                    synonym_parts.append(str(syns))\n",
        "\n",
        "        combined_text = (patient_lower + \" \" + \" \".join(synonym_parts)).lower()\n",
        "\n",
        "        # Diabetes / Hypertension\n",
        "        has_diabetes = contains_root(combined_text, [\"diabet\", \"glucose\", \"blood sugar\"])\n",
        "        has_hypertension = contains_root(combined_text, [\"blood pressure\", \"hypertens\", \"bp\"])\n",
        "\n",
        "        # Heart disease signals\n",
        "        has_heart = contains_root(\n",
        "            combined_text,\n",
        "            [\n",
        "                \"heart\", \"cardiac\",\n",
        "                \"chest pain\", \"chest tightness\", \"chest discomfort\",\n",
        "                \"angina\", \"pain when walking\", \"pain when exercising\",\n",
        "                \"shortness of breath on activity\",\n",
        "                \"heart rate\", \"palpitations\", \"fatigue on exertion\",\n",
        "                \"electric pumping\"\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # COPD signals\n",
        "        has_copd_core = contains_root(\n",
        "            combined_text,\n",
        "            [\"copd\", \"chronic obstructive\", \"emphysema\", \"chronic bronchitis\"]\n",
        "        )\n",
        "        has_copd_symptoms = contains_root(combined_text, [\"breath\"]) and \\\n",
        "                            contains_root(combined_text, [\"mucus\", \"phlegm\", \"sputum\"])\n",
        "\n",
        "        # NEW: COPD indicator = smoking + breathlessness\n",
        "        smoking_and_breath = (\n",
        "            contains_root(combined_text, [\"smok\", \"cigarette\"]) and\n",
        "            contains_root(combined_text, [\"breath\", \"gasp\", \"out of breath\", \"short of breath\"])\n",
        "        )\n",
        "\n",
        "        has_copd = has_copd_core or has_copd_symptoms or smoking_and_breath\n",
        "\n",
        "        # Priority: diabetes\n",
        "        if has_diabetes and not (has_hypertension or has_heart or has_copd):\n",
        "            self.condition_type = \"diabetes\"\n",
        "            return self.condition_type\n",
        "\n",
        "        # Priority: hypertension\n",
        "        if has_hypertension and not (has_diabetes or has_heart or has_copd):\n",
        "            self.condition_type = \"hypertension\"\n",
        "            return self.condition_type\n",
        "\n",
        "        # HEART vs COPD ambiguity -> require disambiguation\n",
        "        if has_heart and has_copd and not (has_diabetes or has_hypertension):\n",
        "            self.condition_type = None\n",
        "            self.awaiting_disambiguation = True\n",
        "            self.possible_conditions = [\"heart_disease\", \"copd\"]\n",
        "            return None\n",
        "\n",
        "        # Unambiguous heart\n",
        "        if has_heart and not has_copd:\n",
        "            self.condition_type = \"heart_disease\"\n",
        "            return self.condition_type\n",
        "\n",
        "        # Unambiguous COPD\n",
        "        if has_copd and not has_heart:\n",
        "            self.condition_type = \"copd\"\n",
        "            return self.condition_type\n",
        "\n",
        "        # Fallback: LLM guess\n",
        "        self.condition_type = self.llm_condition_guess(patient_input)\n",
        "        return self.condition_type\n",
        "\n",
        "    # ------------------------------\n",
        "    # DISAMBIGUATION QUESTION (HEART vs COPD)\n",
        "    # ------------------------------\n",
        "    def get_disambiguation_question(self) -> str:\n",
        "        return (\n",
        "            \"Your symptoms could be related to your heart or to a chronic lung condition.\\n\"\n",
        "            \"Please answer in your own words, or choose one option:\\n\\n\"\n",
        "            \"A) I feel abnormal heart activity such as electric pumping, weird or fast heart beats, \"\n",
        "            \"or a tight band feeling in my upper chest, but I do NOT have heavy mucus or phlegm.\\n\\n\"\n",
        "            \"B) I have a long-lasting cough with thick or heavy mucus or phlegm, especially when I smoke, \"\n",
        "            \"or when I am around dust, fumes, or pollution.\"\n",
        "        )\n",
        "\n",
        "    # ------------------------------\n",
        "    # DISAMBIGUATION ANSWER HANDLER\n",
        "    # (this is where A/B is turned into heart vs COPD)\n",
        "    # ------------------------------\n",
        "    def handle_disambiguation_answer(self, answer: str) -> str | None:\n",
        "        text = answer.lower()\n",
        "\n",
        "        # Explicit heart indicators\n",
        "        heart_indicators = [\n",
        "            \"electric pump\", \"electric pumping\",\n",
        "            \"weird heart beat\", \"weird heartbeat\",\n",
        "            \"fast heart beat\", \"fast heartbeat\",\n",
        "            \"irregular heart beat\", \"irregular heartbeat\",\n",
        "            \"palpitations\"\n",
        "        ]\n",
        "\n",
        "        # Explicit COPD indicators\n",
        "        copd_indicators = [\n",
        "            \"heavy mucus\", \"thick mucus\", \"a lot of mucus\",\n",
        "            \"mucus\", \"phlegm\", \"cough with mucus\", \"coughing mucus\"\n",
        "        ]\n",
        "\n",
        "        heart_hit = any(ind in text for ind in heart_indicators)\n",
        "        copd_hit = any(ind in text for ind in copd_indicators)\n",
        "\n",
        "        if heart_hit and not copd_hit:\n",
        "            return \"heart_disease\"\n",
        "        if copd_hit and not heart_hit:\n",
        "            return \"copd\"\n",
        "\n",
        "        # If user just answers A or B\n",
        "        if re.search(r\"\\b(a)\\b\", text) and not re.search(r\"\\b(b)\\b\", text):\n",
        "            return \"heart_disease\"\n",
        "        if re.search(r\"\\b(b)\\b\", text) and not re.search(r\"\\b(a)\\b\", text):\n",
        "            return \"copd\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    # ------------------------------\n",
        "    # QUESTION SELECTION\n",
        "    # ------------------------------\n",
        "    def should_skip_question(self, question: str) -> bool:\n",
        "        q = question.lower()\n",
        "        if \"glucose\" in q and \"glucose\" in self.extracted_info:\n",
        "            return True\n",
        "        if \"blood pressure\" in q and \"blood_pressure\" in self.extracted_info:\n",
        "            return True\n",
        "        if \"med\" in q and \"medication\" in self.extracted_info:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def get_next_question(self) -> str | None:\n",
        "        if not self.condition_type:\n",
        "            self.interview_complete = True\n",
        "            return None\n",
        "\n",
        "        qs = MEDICAL_QUESTIONS.get(self.condition_type, [])\n",
        "        while self.current_question_index < len(qs):\n",
        "            q = qs[self.current_question_index]\n",
        "            if self.should_skip_question(q):\n",
        "                self.current_question_index += 1\n",
        "                continue\n",
        "            return q\n",
        "\n",
        "        self.interview_complete = True\n",
        "        return None\n",
        "\n",
        "    # ------------------------------\n",
        "    # CHAT (Q&A OUTPUT)\n",
        "    # ------------------------------\n",
        "    def chat(self, user_message: str, next_question: str | None = None) -> str:\n",
        "        self.full_conversation.append(f\"Patient: {user_message}\")\n",
        "        # still extract info from every answer\n",
        "        self.extract_info_from_text(user_message)\n",
        "\n",
        "        if next_question:\n",
        "            response_text = next_question\n",
        "        else:\n",
        "            response_text = \"Thank you. I’ve collected your answers and will analyze them now.\"\n",
        "\n",
        "        self.full_conversation.append(f\"Agent: {response_text}\")\n",
        "        return response_text\n",
        "\n",
        "    # ------------------------------\n",
        "    # INTERVIEW CONTROL\n",
        "    # ------------------------------\n",
        "    def start_interview(self, initial_message: str) -> str:\n",
        "        self.extract_info_from_text(initial_message)\n",
        "        self.identify_condition(initial_message)\n",
        "\n",
        "        # Ambiguous heart vs COPD → ask disambiguation Q (A/B)\n",
        "        if self.awaiting_disambiguation and self.possible_conditions == [\"heart_disease\", \"copd\"]:\n",
        "            question = self.get_disambiguation_question()\n",
        "            self.full_conversation.append(f\"Patient: {initial_message}\")\n",
        "            self.full_conversation.append(f\"Agent: {question}\")\n",
        "            return question\n",
        "\n",
        "        # Unknown condition\n",
        "        if not self.condition_type:\n",
        "            self.interview_complete = True\n",
        "            return \"Sorry, I can only assist with diabetes, hypertension, heart disease, or COPD.\"\n",
        "\n",
        "        # Normal question flow\n",
        "        self.current_question_index = 0\n",
        "        first_q = self.get_next_question()\n",
        "        return self.chat(initial_message, first_q)\n",
        "\n",
        "    def continue_interview(self, patient_response: str) -> str:\n",
        "        # 1) Handle disambiguation answer FIRST (A/B etc.)\n",
        "        if self.awaiting_disambiguation and self.possible_conditions == [\"heart_disease\", \"copd\"]:\n",
        "            chosen = self.handle_disambiguation_answer(patient_response)\n",
        "\n",
        "            if not chosen:\n",
        "                # Fallback to LLM but prefer heart/copd\n",
        "                guess = self.llm_condition_guess(patient_response)\n",
        "                if guess in [\"heart_disease\", \"copd\"]:\n",
        "                    chosen = guess\n",
        "                else:\n",
        "                    # Last resort default\n",
        "                    chosen = \"heart_disease\"\n",
        "\n",
        "            # Now we have the final condition_type\n",
        "            self.condition_type = chosen\n",
        "            self.awaiting_disambiguation = False\n",
        "            self.current_question_index = 0  # start questions for that category\n",
        "\n",
        "            next_q = self.get_next_question()\n",
        "            return self.chat(patient_response, next_q)\n",
        "\n",
        "        # 2) Normal Q&A flow (save answer to previous question)\n",
        "        if self.condition_type:\n",
        "            qs = MEDICAL_QUESTIONS.get(self.condition_type, [])\n",
        "            if 0 <= self.current_question_index < len(qs):\n",
        "                prev_q = qs[self.current_question_index]\n",
        "                self.answers[prev_q] = patient_response\n",
        "\n",
        "        self.current_question_index += 1\n",
        "        next_q = self.get_next_question()\n",
        "        return self.chat(patient_response, next_q)\n",
        "\n",
        "    # ------------------------------\n",
        "    # COLLECTED DATA\n",
        "    # ------------------------------\n",
        "    def get_collected_data(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"condition_type\": self.condition_type,\n",
        "            \"interview_complete\": self.interview_complete,\n",
        "            \"qa_data\": {**self.answers, **self.extracted_info},\n",
        "            \"full_conversation\": self.full_conversation,\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"✓ SymptomQAAgent (Q&A with heart/COPD disambiguation) is loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72bf2986",
      "metadata": {
        "id": "72bf2986"
      },
      "source": [
        "## Agent 2 : Analysis Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "93274a01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93274a01",
        "outputId": "0b655490-21ff-4ad4-f55a-a8a97dc84eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Analysis Agent ready with LLM-driven severity and safety override!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "class AnalysisAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    # ✅ Public method (new style)\n",
        "    def estimate_severity(self, qa_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Public method to estimate severity.\n",
        "        Wrapper around the internal LLM-based method.\n",
        "        \"\"\"\n",
        "        return self._estimate_severity_llm(qa_data)\n",
        "\n",
        "    # ✅ Backward-compatible alias (for any code that uses .estimateseverity)\n",
        "    def estimateseverity(self, qa_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Alias to keep old code working.\n",
        "        \"\"\"\n",
        "        return self.estimate_severity(qa_data)\n",
        "\n",
        "    def _estimate_severity_llm(self, qa_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Ask the LLM to classify severity into:\n",
        "        - CRITICAL\n",
        "        - HIGH\n",
        "        - MODERATE\n",
        "        - LOW\n",
        "\n",
        "        Then enforce some safety rules (e.g., red_flag -> at least CRITICAL).\n",
        "        \"\"\"\n",
        "        data = qa_data.get(\"qa_data\", {})\n",
        "        full_conv = qa_data.get(\"full_conversation\", [])\n",
        "\n",
        "        red_flag_present = \"red_flag\" in data\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a medical triage assistant (not a doctor).\n",
        "Your job is to classify the OVERALL severity of this case into ONE of four labels:\n",
        "\n",
        "- CRITICAL  = life-threatening red-flag symptoms, needs emergency care NOW.\n",
        "- HIGH      = serious symptoms or unstable control, needs urgent (same day / 24h) medical review.\n",
        "- MODERATE  = significant but not immediately dangerous, needs medical review within a few days.\n",
        "- LOW       = mild, stable, routine follow-up is sufficient.\n",
        "\n",
        "You MUST respond ONLY in JSON with this format:\n",
        "{{\n",
        "  \"severity_label\": \"CRITICAL|HIGH|MODERATE|LOW\",\n",
        "  \"reason\": \"short explanation of why you chose this label\"\n",
        "}}\n",
        "\n",
        "Here is the structured data:\n",
        "\n",
        "Condition type: {qa_data.get(\"condition_type\", \"unknown\")}\n",
        "\n",
        "Conversation:\n",
        "{chr(10).join(full_conv)}\n",
        "\n",
        "Collected QA data:\n",
        "{json.dumps(data, indent=2)}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            raw = self.llm.invoke(prompt).content.strip()\n",
        "            parsed = json.loads(raw)\n",
        "            label = str(parsed.get(\"severity_label\", \"\")).upper().strip()\n",
        "        except Exception:\n",
        "            # Fallback if parsing fails\n",
        "            label = \"MODERATE\"\n",
        "\n",
        "        # Normalize to allowed set\n",
        "        allowed = {\"CRITICAL\", \"HIGH\", \"MODERATE\", \"LOW\"}\n",
        "        if label not in allowed:\n",
        "            label = \"MODERATE\"\n",
        "\n",
        "        # Safety override: if red_flag present, upgrade to CRITICAL if LLM was too soft\n",
        "        if red_flag_present and label in {\"LOW\", \"MODERATE\"}:\n",
        "            label = \"CRITICAL\"\n",
        "\n",
        "        return label\n",
        "\n",
        "    def analyze(self, qa_data: Dict) -> str:\n",
        "        # Let LLM be responsible for severity (with our safety override)\n",
        "        computed_severity = self._estimate_severity_llm(qa_data)\n",
        "\n",
        "        # Map internal condition_type to a readable disease name\n",
        "        condition_key = qa_data.get(\"condition_type\", \"unknown\")\n",
        "        condition_name_map = {\n",
        "            \"copd\": \"Chronic Obstructive Pulmonary Disease (COPD)\",\n",
        "            \"diabetes\": \"Diabetes\",\n",
        "            \"hypertension\": \"Hypertension\",\n",
        "            \"heart_disease\": \"Heart Disease\",\n",
        "        }\n",
        "        condition_name = condition_name_map.get(condition_key, condition_key)\n",
        "\n",
        "        prompt = f\"\"\"You are a medical triage summarizer for a symptom-checking AI.\n",
        "You are NOT a doctor and cannot diagnose, but you can summarize and triage.\n",
        "\n",
        "You MUST use the SEVERITY_LABEL exactly as given below.\n",
        "\n",
        "Condition key: {condition_key}\n",
        "Condition name: {condition_name}\n",
        "\n",
        "FINAL TRIAGE SEVERITY (already decided):\n",
        "- SEVERITY_LABEL: {computed_severity}\n",
        "\n",
        "Full Conversation:\n",
        "{chr(10).join(qa_data.get('full_conversation', []))}\n",
        "\n",
        "Collected Data (questions + extracted info):\n",
        "{json.dumps(qa_data.get('qa_data', {}), indent=2)}\n",
        "\n",
        "TASK:\n",
        "Based on the FINAL TRIAGE SEVERITY and the data above, write a brief analysis:\n",
        "\n",
        "0. *CONDITION NAME:* Use this exact label: {condition_name}\n",
        "\n",
        "1. *SEVERITY:* Use EXACTLY this label: {computed_severity}\n",
        "2. *KEY FINDINGS:* List 2–4 key clinical points (mention any red flags if present, or say 'No red flags reported').\n",
        "3. *MEDICATION:* Comment briefly on whether they seem compliant or not (based on answers, or say 'Not enough information').\n",
        "4. *URGENCY:* Suggest a timeframe using the severity (e.g., 'Immediate emergency care', 'Within 24 hours', 'Within a few days', 'Routine follow-up').\n",
        "5. *RECOMMENDATIONS:* 3–4 short, practical suggestions (self-monitoring, lifestyle, and when to seek urgent help).\n",
        "   Always remind that this is NOT a diagnosis and they must seek a real doctor.\n",
        "\n",
        "Be concise, clear, and non-alarming.\n",
        "Do NOT change the SEVERITY label or the CONDITION NAME.\n",
        "\"\"\"\n",
        "        response = self.llm.invoke(prompt).content\n",
        "        return response\n",
        "\n",
        "\n",
        "print(\"✓ Analysis Agent ready with LLM-driven severity and safety override!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f72a6bd",
      "metadata": {
        "id": "9f72a6bd"
      },
      "source": [
        "## Agent 4 : Planning Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ff4e8f3a",
      "metadata": {
        "id": "ff4e8f3a"
      },
      "outputs": [],
      "source": [
        "class PlanningAgent:\n",
        "    \"\"\"\n",
        "    PlanningAgent:\n",
        "    --------------\n",
        "    Takes a condition_type + severity_label and simulates different treatment / lifestyle plans.\n",
        "    Uses the LLM only to generate a short, patient-friendly explanation for each plan.\n",
        "\n",
        "    NOTE: This is NOT real medical advice. It's only for educational / simulation purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "        # Core library of scenario plans\n",
        "        # Each plan has:\n",
        "        #   - name\n",
        "        #   - base_success (0–1)\n",
        "        #   - side_effects\n",
        "        #   - nutrition\n",
        "        #   - therapy  (education / rehab / counseling)\n",
        "        #   - sports   (exercise / activity)\n",
        "        #   - monitoring (what to track at home / clinic)\n",
        "        self.condition_plans = {\n",
        "            # ==========================\n",
        "            # DIABETES (all 4 severities)\n",
        "            # ==========================\n",
        "            \"diabetes\": {\n",
        "                \"CRITICAL\": [\n",
        "                    {\n",
        "                        \"name\": \"Emergency hospital care + IV insulin + fluids\",\n",
        "                        \"base_success\": 0.78,\n",
        "                        \"side_effects\": \"Risk of low blood sugar, electrolyte imbalance, hospital complications.\",\n",
        "                        \"nutrition\": \"Nothing by mouth initially; then gradual re-introduction of diabetic-friendly meals.\",\n",
        "                        \"therapy\": \"Intensive diabetes education once stable; review of injection technique and sick-day rules.\",\n",
        "                        \"sports\": \"No exercise during acute crisis; later, short supervised walking when allowed.\",\n",
        "                        \"monitoring\": \"Continuous glucose checks, blood pressure, urine ketones, and electrolytes.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"HIGH\": [\n",
        "                    {\n",
        "                        \"name\": \"Basal-bolus insulin + structured diet + close follow-up\",\n",
        "                        \"base_success\": 0.85,\n",
        "                        \"side_effects\": \"Risk of hypoglycemia, weight gain if calories not controlled.\",\n",
        "                        \"nutrition\": \"Three main meals and 2–3 snacks, carb counting, avoid sugary drinks.\",\n",
        "                        \"therapy\": \"One-to-one diabetes education, insulin titration plan, psychological support if needed.\",\n",
        "                        \"sports\": \"Gentle daily walking (10–20 min) once glucose is stabilized.\",\n",
        "                        \"monitoring\": \"Home glucose monitoring several times per day, symptom diary, regular clinic visits.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"MODERATE\": [\n",
        "                    {\n",
        "                        \"name\": \"Oral meds (e.g., metformin) + diet overhaul + regular aerobic exercise\",\n",
        "                        \"base_success\": 0.92,\n",
        "                        \"side_effects\": \"Possible GI upset, mild nausea early on.\",\n",
        "                        \"nutrition\": \"Balanced meals with high fiber, low refined sugar, controlled portions.\",\n",
        "                        \"therapy\": \"Group diabetes education, nutrition counseling, weight management plan.\",\n",
        "                        \"sports\": \"30 minutes brisk walking 5x/week, light strength training 2x/week.\",\n",
        "                        \"monitoring\": \"Home glucose checks as advised, weight tracking, blood tests every few months.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"LOW\": [\n",
        "                    {\n",
        "                        \"name\": \"Lifestyle-focused plan: weight control + healthy diet + light activity\",\n",
        "                        \"base_success\": 0.97,\n",
        "                        \"side_effects\": \"Minimal risk if no medications used.\",\n",
        "                        \"nutrition\": \"Mediterranean or DASH-style diet; lots of vegetables, lean proteins, whole grains.\",\n",
        "                        \"therapy\": \"Lifestyle coaching, digital apps to track calories/steps.\",\n",
        "                        \"sports\": \"Daily walking, stretching, yoga or low-impact sports.\",\n",
        "                        \"monitoring\": \"Periodic glucose and A1c checks, self-monitoring of weight and symptoms.\"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "\n",
        "            # ==========================\n",
        "            # HEART DISEASE (all 4)\n",
        "            # ==========================\n",
        "            \"heart_disease\": {\n",
        "                \"CRITICAL\": [\n",
        "                    {\n",
        "                        \"name\": \"Emergency cardiac care + oxygen + strict bedrest\",\n",
        "                        \"base_success\": 0.75,\n",
        "                        \"side_effects\": \"Risk of invasive procedures, bleeding, hospital-acquired complications.\",\n",
        "                        \"nutrition\": \"Cardiac hospital diet; low salt, limited fluids, avoid heavy meals.\",\n",
        "                        \"therapy\": \"Continuous cardiac monitoring, possible interventions (stents, procedures).\",\n",
        "                        \"sports\": \"No exercise; only passive limb movements in bed as allowed.\",\n",
        "                        \"monitoring\": \"Telemetry, frequent vitals, ECGs, lab markers (troponin, etc.).\"\n",
        "                    }\n",
        "                ],\n",
        "                \"HIGH\": [\n",
        "                    {\n",
        "                        \"name\": \"Hospital treatment + optimized meds + restricted activity\",\n",
        "                        \"base_success\": 0.80,\n",
        "                        \"side_effects\": \"Potential low blood pressure, kidney issues, medication side effects.\",\n",
        "                        \"nutrition\": \"Low-salt, fluid-restricted diet if heart failure present.\",\n",
        "                        \"therapy\": \"Inpatient cardiac education, discharge planning, smoking cessation if relevant.\",\n",
        "                        \"sports\": \"Bed-to-chair transfers only, short supervised standing/walking.\",\n",
        "                        \"monitoring\": \"Daily weight, oxygen saturation, blood pressure, heart rate logs.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"MODERATE\": [\n",
        "                    {\n",
        "                        \"name\": \"Outpatient meds + cardiac rehab + graded exercise\",\n",
        "                        \"base_success\": 0.90,\n",
        "                        \"side_effects\": \"Dizziness, fatigue, possible medication-related side effects.\",\n",
        "                        \"nutrition\": \"Heart-healthy diet: low salt, high vegetables, healthy fats (olive oil, nuts).\",\n",
        "                        \"therapy\": \"Structured cardiac rehab program with supervised sessions.\",\n",
        "                        \"sports\": \"Short walks, light cycling or treadmill as tolerated, no heavy lifting.\",\n",
        "                        \"monitoring\": \"Home BP and pulse diary, symptom log (chest pain, breathlessness, swelling).\"\n",
        "                    }\n",
        "                ],\n",
        "                \"LOW\": [\n",
        "                    {\n",
        "                        \"name\": \"Long-term prevention: lifestyle optimization + regular follow-up\",\n",
        "                        \"base_success\": 0.97,\n",
        "                        \"side_effects\": \"Minimal; usually related to low-dose meds if any.\",\n",
        "                        \"nutrition\": \"Mediterranean-style diet, limit trans fats and processed foods.\",\n",
        "                        \"therapy\": \"Lifestyle counseling, stress management (breathing, relaxation).\",\n",
        "                        \"sports\": \"Swimming, walking, biking; moderate intensity most days of the week.\",\n",
        "                        \"monitoring\": \"Annual heart check-ups, lipid panel, blood pressure monitoring.\"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "\n",
        "            # ==========================\n",
        "            # COPD (all 4)\n",
        "            # ==========================\n",
        "            \"copd\": {\n",
        "                \"CRITICAL\": [\n",
        "                    {\n",
        "                        \"name\": \"ICU-level care + oxygen + possible ventilation\",\n",
        "                        \"base_success\": 0.65,\n",
        "                        \"side_effects\": \"High risk of infection, delirium, complications from ventilation.\",\n",
        "                        \"nutrition\": \"High-calorie, high-protein small meals to reduce breathing effort.\",\n",
        "                        \"therapy\": \"Intensive respiratory therapy, frequent suctioning, chest physiotherapy.\",\n",
        "                        \"sports\": \"No active sports; only passive limb movements as tolerated.\",\n",
        "                        \"monitoring\": \"Blood gases, oxygen saturation, respiratory rate, signs of fatigue/exhaustion.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"HIGH\": [\n",
        "                    {\n",
        "                        \"name\": \"Hospital therapy + inhalers + oxygen + minimal activity\",\n",
        "                        \"base_success\": 0.70,\n",
        "                        \"side_effects\": \"Possible shakiness, palpitations, dry mouth from inhalers.\",\n",
        "                        \"nutrition\": \"Small frequent meals, avoid gas-forming foods that worsen breathlessness.\",\n",
        "                        \"therapy\": \"Pulmonary physical therapy, breathing techniques training (pursed-lip breathing).\",\n",
        "                        \"sports\": \"Bed-to-chair transfers, very short hallway walks with assistance.\",\n",
        "                        \"monitoring\": \"Oxygen saturation, dyspnea scale, sputum amount/color, temperature.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"MODERATE\": [\n",
        "                    {\n",
        "                        \"name\": \"Inhaler optimization + pulmonary rehab + gentle exercise\",\n",
        "                        \"base_success\": 0.82,\n",
        "                        \"side_effects\": \"Tremor, mild palpitations, dry throat.\",\n",
        "                        \"nutrition\": \"Anti-inflammatory diet with fruits, vegetables, adequate protein.\",\n",
        "                        \"therapy\": \"Scheduled pulmonary rehab sessions and self-management education.\",\n",
        "                        \"sports\": \"Gentle walking, short cycling, avoid cold or polluted air.\",\n",
        "                        \"monitoring\": \"Daily symptom score, inhaler use log, check for flare triggers.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"LOW\": [\n",
        "                    {\n",
        "                        \"name\": \"Stable COPD management + activity + trigger avoidance\",\n",
        "                        \"base_success\": 0.90,\n",
        "                        \"side_effects\": \"Usually mild if inhalers used correctly.\",\n",
        "                        \"nutrition\": \"Balanced diet, keep hydrated, maintain healthy body weight.\",\n",
        "                        \"therapy\": \"Support group, smoking cessation if relevant, regular check-ups.\",\n",
        "                        \"sports\": \"Walking, light swimming, breathing exercises, paced activities.\",\n",
        "                        \"monitoring\": \"Monitor shortness of breath trends, rescue inhaler use, annual spirometry.\"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "\n",
        "            # ==========================\n",
        "            # HYPERTENSION (optional, but kept)\n",
        "            # ==========================\n",
        "            \"hypertension\": {\n",
        "                \"CRITICAL\": [\n",
        "                    {\n",
        "                        \"name\": \"Hypertensive emergency management in hospital\",\n",
        "                        \"base_success\": 0.80,\n",
        "                        \"side_effects\": \"Risk of rapid BP drops, kidney injury, electrolyte shifts.\",\n",
        "                        \"nutrition\": \"Strict low-salt diet, careful fluid control.\",\n",
        "                        \"therapy\": \"Continuous BP monitoring, adjustment of IV and oral medications.\",\n",
        "                        \"sports\": \"No exercise during crisis; gradual mobilization later.\",\n",
        "                        \"monitoring\": \"Frequent BP checks (every minutes to hours), kidney function tests.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"HIGH\": [\n",
        "                    {\n",
        "                        \"name\": \"Combination antihypertensives + strict low-salt diet\",\n",
        "                        \"base_success\": 0.85,\n",
        "                        \"side_effects\": \"Dizziness, electrolyte imbalance, cough with some drugs.\",\n",
        "                        \"nutrition\": \"DASH diet, minimal processed foods, avoid salty snacks & canned foods.\",\n",
        "                        \"therapy\": \"Medication education, adherence support, stress management strategies.\",\n",
        "                        \"sports\": \"Short daily walks, avoid heavy lifting or intense exertion until BP improves.\",\n",
        "                        \"monitoring\": \"Home BP log (morning/evening), regular clinic checks.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"MODERATE\": [\n",
        "                    {\n",
        "                        \"name\": \"Single agent (e.g., ACE inhibitor) + DASH diet + regular walking\",\n",
        "                        \"base_success\": 0.88,\n",
        "                        \"side_effects\": \"Possible cough, mild dizziness when standing quickly.\",\n",
        "                        \"nutrition\": \"High in fruits/vegetables, low-fat dairy, low salt.\",\n",
        "                        \"therapy\": \"Self-monitoring training, phone or app reminders for meds.\",\n",
        "                        \"sports\": \"Daily walking 20–30 min, yoga or stretching.\",\n",
        "                        \"monitoring\": \"Home BP 2–3x/week, keep a simple notebook or phone log.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"LOW\": [\n",
        "                    {\n",
        "                        \"name\": \"Lifestyle-only approach: diet + exercise + stress control\",\n",
        "                        \"base_success\": 0.95,\n",
        "                        \"side_effects\": \"None (if no meds).\",\n",
        "                        \"nutrition\": \"Salt restriction, more potassium-rich foods (fruits, vegetables).\",\n",
        "                        \"therapy\": \"Relaxation training, mindfulness, sleep hygiene.\",\n",
        "                        \"sports\": \"Any enjoyable aerobic activity (walking, cycling, dancing) most days.\",\n",
        "                        \"monitoring\": \"Periodic BP checks at home or pharmacy, annual medical visits.\"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "\n",
        "\n",
        "            }\n",
        "\n",
        "    def compare_plans(self, severity_label: str, condition_type: str, analysis_text: str = None):\n",
        "        \"\"\"\n",
        "        Chooses appropriate plans based on condition_type and severity_label,\n",
        "        asks the LLM for a short patient-friendly explanation, and prints them.\n",
        "\n",
        "        severity_label: \"CRITICAL\" | \"HIGH\" | \"MODERATE\" | \"LOW\"\n",
        "        condition_type: \"diabetes\" | \"heart_disease\" | \"hypertension\" | \"copd\" | \"asthma\"\n",
        "        analysis_text:  the text coming from AnalysisAgent.analyze(...) (optional)\n",
        "        \"\"\"\n",
        "        print(\"\\n----- Planning Agent Simulation -----\")\n",
        "\n",
        "        condition_type = (condition_type or \"\").lower().strip()\n",
        "        severity_label = (severity_label or \"\").upper().strip()\n",
        "\n",
        "        # Primary attempt: use the exact severity\n",
        "        plans = self.condition_plans.get(condition_type, {}).get(severity_label)\n",
        "\n",
        "        # If no plans found, try mapping CRITICAL -> HIGH as fallback\n",
        "        if not plans:\n",
        "            if severity_label == \"CRITICAL\":\n",
        "                plans = self.condition_plans.get(condition_type, {}).get(\"HIGH\")\n",
        "\n",
        "        # If still nothing, we can't simulate a specific plan\n",
        "        if not plans:\n",
        "            print(\"No specific treatment scenarios for this condition/severity. Refer to medical guidelines.\")\n",
        "            return\n",
        "\n",
        "        for plan in plans:\n",
        "            base = plan[\"base_success\"]\n",
        "            prompt = (\n",
        "                f\"Patient summary (from analysis step):\\n{analysis_text}\\n\\n\"\n",
        "                f\"Condition: {condition_type}, Severity: {severity_label}\\n\"\n",
        "                f\"Proposed plan:\\n\"\n",
        "                f\"  - Name: {plan['name']}\\n\"\n",
        "                f\"  - Nutrition: {plan['nutrition']}\\n\"\n",
        "                f\"  - Therapy/Rehab: {plan['therapy']}\\n\"\n",
        "                f\"  - Exercise/Sports: {plan['sports']}\\n\"\n",
        "                f\"  - Monitoring: {plan['monitoring']}\\n\"\n",
        "                f\"  - Predicted Success: {int(base*100)}%\\n\"\n",
        "                f\"  - Side Effects: {plan['side_effects']}\\n\\n\"\n",
        "                f\"Task: In 4–6 short sentences, explain this plan to the patient \"\n",
        "                f\"in simple, kind language. Emphasize that it does NOT replace a real doctor, \"\n",
        "                f\"and they must follow their own clinician's advice.\"\n",
        "            )\n",
        "\n",
        "            advice = self.llm.invoke(prompt).content\n",
        "\n",
        "            print(\n",
        "                f\"\\nPlan: {plan['name']}\"\n",
        "                f\"\\n  Predicted improvement: {int(base*100)}%\"\n",
        "                f\"\\n  Side effects: {plan['side_effects']}\"\n",
        "                f\"\\n  Nutrition: {plan['nutrition']}\"\n",
        "                f\"\\n  Therapy/Rehab: {plan['therapy']}\"\n",
        "                f\"\\n  Sports/Exercise: {plan['sports']}\"\n",
        "                f\"\\n  Monitoring: {plan['monitoring']}\"\n",
        "                f\"\\n  Advice: {advice}\\n\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d17bdc",
      "metadata": {
        "id": "f5d17bdc"
      },
      "source": [
        "## AGENT 5 : Coordinator Agent (Reports and sending it to DTwin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4d0488b0",
      "metadata": {
        "id": "4d0488b0"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Any, List\n",
        "\n",
        "class CoordinatorAgent:\n",
        "    \"\"\"\n",
        "    CoordinatorAgent\n",
        "    ----------------\n",
        "    High-level agent that:\n",
        "      1) Runs AnalysisAgent (triage + severity + summary)\n",
        "      2) Uses PlanningAgent to build treatment/lifestyle plans\n",
        "      3) Returns a single structured report for doctors / nurses / caregivers.\n",
        "\n",
        "    It does NOT replace AnalysisAgent or PlanningAgent – it just orchestrates them.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.analysis_agent = AnalysisAgent(llm)\n",
        "        self.planning_agent = PlanningAgent(llm)\n",
        "\n",
        "    # 🔧 Helper to get severity label regardless of which method name exists\n",
        "    def _get_severity_label(self, qa_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        Try different method names depending on how AnalysisAgent is implemented.\n",
        "        This makes CoordinatorAgent compatible with multiple versions.\n",
        "        \"\"\"\n",
        "        if hasattr(self.analysis_agent, \"estimate_severity\"):\n",
        "            return self.analysis_agent.estimate_severity(qa_data)\n",
        "        if hasattr(self.analysis_agent, \"estimateseverity\"):\n",
        "            return self.analysis_agent.estimateseverity(qa_data)\n",
        "        if hasattr(self.analysis_agent, \"_estimate_severity_llm\"):\n",
        "            return self.analysis_agent._estimate_severity_llm(qa_data)\n",
        "        # Fallback if something is really wrong\n",
        "        return \"MODERATE\"\n",
        "\n",
        "    def run_full_pipeline(self, qa_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            qa_data = qaagent.get_collected_data()\n",
        "\n",
        "        Output:\n",
        "            A structured report dict:\n",
        "            {\n",
        "              \"condition_type\": ...,\n",
        "              \"severity_label\": ...,\n",
        "              \"analysis_text\": ...,\n",
        "              \"plans\": [ ...list of plan dicts... ],\n",
        "              \"approved_by_clinician\": False,\n",
        "              \"timestamp\": \"TO_FILL_BY_APP\"\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # 1) Run analysis (triage + severity)\n",
        "        analysis_text = self.analysis_agent.analyze(qa_data)\n",
        "        severity_label = self._get_severity_label(qa_data)\n",
        "        condition_type = qa_data.get(\"condition_type\", \"unknown\")\n",
        "\n",
        "        # 2) Collect treatment / lifestyle plans (without printing)\n",
        "        plans_data = self._collect_plans(severity_label, condition_type, analysis_text)\n",
        "\n",
        "        # 3) Build unified report\n",
        "        report = {\n",
        "            \"condition_type\": condition_type,\n",
        "            \"severity_label\": severity_label,\n",
        "            \"analysis_text\": analysis_text,\n",
        "            \"plans\": plans_data,\n",
        "            \"approved_by_clinician\": False,   # doctor can toggle this in UI / DB\n",
        "            \"timestamp\": \"TO_FILL_BY_APP\",    # you can fill with datetime later\n",
        "        }\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _collect_plans(self, severity_label: str, condition_type: str, analysis_text: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Internal helper:\n",
        "        Reuses PlanningAgent.condition_plans but returns structured data instead of printing.\n",
        "        \"\"\"\n",
        "\n",
        "        condition_type_norm = (condition_type or \"\").lower().strip()\n",
        "        severity_label_norm = (severity_label or \"\").upper().strip()\n",
        "\n",
        "        # Same lookup logic as compare_plans\n",
        "        plans = self.planning_agent.condition_plans.get(condition_type_norm, {}).get(severity_label_norm)\n",
        "\n",
        "        # Fallback: CRITICAL -> HIGH if needed\n",
        "        if not plans and severity_label_norm == \"CRITICAL\":\n",
        "            plans = self.planning_agent.condition_plans.get(condition_type_norm, {}).get(\"HIGH\")\n",
        "\n",
        "        if not plans:\n",
        "            return []\n",
        "\n",
        "        results: List[Dict[str, Any]] = []\n",
        "\n",
        "        for plan in plans:\n",
        "            base = plan[\"base_success\"]\n",
        "            prompt = (\n",
        "                f\"Patient summary (from analysis step):\\n{analysis_text}\\n\\n\"\n",
        "                f\"Condition: {condition_type_norm}, Severity: {severity_label_norm}\\n\"\n",
        "                f\"Proposed plan:\\n\"\n",
        "                f\"  - Name: {plan['name']}\\n\"\n",
        "                f\"  - Nutrition: {plan['nutrition']}\\n\"\n",
        "                f\"  - Therapy/Rehab: {plan['therapy']}\\n\"\n",
        "                f\"  - Exercise/Sports: {plan['sports']}\\n\"\n",
        "                f\"  - Monitoring: {plan['monitoring']}\\n\"\n",
        "                f\"  - Predicted Success: {int(base*100)}%\\n\"\n",
        "                f\"  - Side Effects: {plan['side_effects']}\\n\\n\"\n",
        "                f\"Task: In 4–6 short sentences, explain this plan to the patient \"\n",
        "                f\"in simple, kind language. Emphasize that it does NOT replace a real doctor, \"\n",
        "                f\"and they must follow their own clinician's advice.\"\n",
        "            )\n",
        "\n",
        "            advice = self.llm.invoke(prompt).content\n",
        "\n",
        "            results.append({\n",
        "                \"name\": plan[\"name\"],\n",
        "                \"predicted_improvement_percent\": int(base * 100),\n",
        "                \"side_effects\": plan[\"side_effects\"],\n",
        "                \"nutrition\": plan[\"nutrition\"],\n",
        "                \"therapy\": plan[\"therapy\"],\n",
        "                \"sports\": plan[\"sports\"],\n",
        "                \"monitoring\": plan[\"monitoring\"],\n",
        "                \"patient_friendly_advice\": advice,\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def send_to_digital_twin(self, report: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Placeholder for future integration with your Digital Twin backend.\n",
        "        For now, just prints a stub message.\n",
        "        (You said you commented out Digital Twin usage, so this is harmless.)\n",
        "        \"\"\"\n",
        "        print(\"⚙️ [Coordinator] Digital Twin sync is currently disabled (stub).\")\n",
        "        # Keep your real integration commented out for now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747fcc03",
      "metadata": {
        "id": "747fcc03"
      },
      "source": [
        "## UserInterface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "251a50c3",
      "metadata": {
        "id": "251a50c3"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# UPDATED USER INTERFACE (NO print, NO input → Streamlit mode)\n",
        "# ============================================================\n",
        "\n",
        "class MedTwinUserInterface:\n",
        "    \"\"\"\n",
        "    This UI no longer prints or asks for input().\n",
        "    It exposes methods for Streamlit to call:\n",
        "        - start_interview()\n",
        "        - next_question()\n",
        "        - get_report()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.qaagent = SymptomQAAgent(llm)\n",
        "        self.analysisagent = AnalysisAgent(llm)\n",
        "        self.planningagent = PlanningAgent(llm)\n",
        "        self.coordinator = CoordinatorAgent(llm)\n",
        "\n",
        "        # UI state\n",
        "        self.current_question = None\n",
        "        self.finished = False\n",
        "        self.qa_data = None\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    def start_interview(self, initial_problem: str):\n",
        "        \"\"\"Initialize interview and return first question.\"\"\"\n",
        "        self.finished = False\n",
        "        self.qaagent.reset()                     # clear previous interview\n",
        "        self.qaagent.initial_symptom = initial_problem\n",
        "\n",
        "        # Identify condition\n",
        "        condition = self.qaagent.identify_condition(initial_problem)\n",
        "        self.qaagent.condition_type = condition\n",
        "\n",
        "        # Get first Q\n",
        "        first_q = self.qaagent.ask_question(initial_problem)\n",
        "        self.current_question = first_q\n",
        "        return first_q\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    def next_question(self, user_answer: str):\n",
        "        \"\"\"Send user answer → get next question OR finish.\"\"\"\n",
        "        next_q = self.qaagent.process_answer(user_answer)\n",
        "        self.current_question = next_q\n",
        "\n",
        "        if next_q is None:\n",
        "            self.finished = True\n",
        "            self.qa_data = self.qaagent.get_collected_data()\n",
        "\n",
        "        return next_q\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    def get_final_report(self):\n",
        "        \"\"\"Run analysis + planning + assemble final report.\"\"\"\n",
        "        if not self.finished:\n",
        "            return None\n",
        "\n",
        "        report = self.coordinator.run_full_pipeline(self.qa_data)\n",
        "        return report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97966ea",
      "metadata": {
        "id": "a97966ea"
      },
      "source": [
        "## Start Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0388e40d",
      "metadata": {
        "id": "0388e40d"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok > /dev/null\n",
        "!kill $(lsof -t -i:8501) 2> /dev/null\n",
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 >/dev/null 2>&1 &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "390ea4fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390ea4fc",
        "outputId": "07fc3387-d2f1-4564-b19b-a07b631c0c70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://uncatastrophically-unobliterated-mario.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "public_url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "a8574a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8574a98",
        "outputId": "12010188-05ce-4af1-972d-8a28abd8ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "# ===========================================\n",
        "# MedTwin – 3-Agent Architecture + Streamlit UI\n",
        "# ===========================================\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Helper functions + Questions\n",
        "# ============================================================\n",
        "def contains_root(text: str, roots: List[str]) -> bool:\n",
        "    for r in roots:\n",
        "        if r in text:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def parse_llm_output(llm_response: str) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Try JSON first, then fall back to empty dict.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(llm_response)\n",
        "        return data if isinstance(data, dict) else {}\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "MEDICAL_QUESTIONS: Dict[str, List[str]] = {\n",
        "    \"diabetes\": [\n",
        "        \"What's your fasting blood sugar level?\",\n",
        "        \"Have you noticed increased thirst or urination?\",\n",
        "        \"Any recent fatigue or blurred vision?\",\n",
        "    ],\n",
        "    \"hypertension\": [\n",
        "        \"What's your blood pressure reading?\",\n",
        "        \"Any headaches, dizziness, or chest discomfort?\",\n",
        "        \"Are you taking your hypertension medications?\",\n",
        "    ],\n",
        "    \"heart_disease\": [\n",
        "        \"Are you having any chest pain, tightness, or pressure right now?\",\n",
        "        \"Does any chest discomfort get worse when you walk, climb stairs, or exercise?\",\n",
        "        \"Do you feel short of breath during simple activities like walking or talking?\",\n",
        "        \"Have you noticed your heart beating fast, slow, or irregularly?\",\n",
        "        \"Do your legs, feet, or ankles swell by the end of the day?\",\n",
        "        \"Do your symptoms improve when you rest?\",\n",
        "    ],\n",
        "    \"copd\": [\n",
        "        \"How's your breathing today (1–10)?\",\n",
        "        \"Are you coughing or producing mucus?\",\n",
        "        \"Have you used your inhaler/bronchodilator recently?\",\n",
        "        \"Any chest tightness or wheezing?\",\n",
        "        \"Have you been around smoke, dust, or pollution today?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SymptomQAAgent – corrected full version\n",
        "# ============================================================\n",
        "class SymptomQAAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.reset()\n",
        "\n",
        "    # ---------------- RESET STATE ----------------\n",
        "    def reset(self):\n",
        "        self.full_conversation: List[str] = []\n",
        "        self.extracted_info: Dict[str, Any] = {}\n",
        "        self.answers: Dict[str, str] = {}\n",
        "\n",
        "        self.condition_type: str | None = None\n",
        "        self.current_question_index: int = 0\n",
        "        self.interview_complete: bool = False\n",
        "\n",
        "        # Disambiguation state\n",
        "        self.awaiting_disambiguation: bool = False\n",
        "        self.possible_conditions: List[str] = []\n",
        "\n",
        "    # ---------------- RULE-BASED EXTRACTION ----------------\n",
        "    def rule_based_extract(self, text: str):\n",
        "        lower = text.lower()\n",
        "\n",
        "        # timing\n",
        "        if re.search(r\"\\bfor (\\d+) (day|week|hour)s?\\b\", lower):\n",
        "            self.extracted_info[\"timing\"] = text\n",
        "\n",
        "        # severity (e.g. 7/10 or mild/moderate/severe)\n",
        "        if re.search(r\"(\\d+)\\s*/\\s*10\", lower) or any(\n",
        "            w in lower for w in [\"mild\", \"moderate\", \"severe\", \"unbearable\"]\n",
        "        ):\n",
        "            self.extracted_info[\"severity\"] = text\n",
        "\n",
        "        # glucose\n",
        "        if any(k in lower for k in [\"glucose\", \"blood sugar\", \"mg/dl\", \"mmol\"]):\n",
        "            self.extracted_info[\"glucose\"] = text\n",
        "\n",
        "        # blood pressure\n",
        "        if (\n",
        "            re.search(r\"\\d+/\\d+\", lower)\n",
        "            or \"blood pressure\" in lower\n",
        "            or \"bp\" in lower\n",
        "        ):\n",
        "            self.extracted_info[\"blood_pressure\"] = text\n",
        "\n",
        "        # mucus / cough\n",
        "        if any(k in lower for k in [\"mucus\", \"phlegm\", \"sputum\", \"cough\"]):\n",
        "            self.extracted_info[\"cough_mucus\"] = text\n",
        "\n",
        "        # smoking / triggers\n",
        "        if any(\n",
        "            k in lower\n",
        "            for k in [\"smoke\", \"smoking\", \"cigarette\", \"dust\", \"pollution\", \"fumes\"]\n",
        "        ):\n",
        "            self.extracted_info[\"resp_triggers\"] = text\n",
        "\n",
        "        # breathing difficulty\n",
        "        if any(\n",
        "            k in lower\n",
        "            for k in [\n",
        "                \"shortness of breath\",\n",
        "                \"can't breathe\",\n",
        "                \"cannot breathe\",\n",
        "                \"dyspnea\",\n",
        "                \"out of breath\",\n",
        "                \"gasping\",\n",
        "                \"hard to breathe\",\n",
        "            ]\n",
        "        ):\n",
        "            self.extracted_info[\"breathing_status\"] = text\n",
        "\n",
        "        # red flags\n",
        "        if any(\n",
        "            k in lower\n",
        "            for k in [\n",
        "                \"severe chest pain\",\n",
        "                \"crushing chest pain\",\n",
        "                \"blue lips\",\n",
        "                \"blue face\",\n",
        "                \"passed out\",\n",
        "                \"fainted\",\n",
        "            ]\n",
        "        ):\n",
        "            self.extracted_info[\"red_flag\"] = text\n",
        "\n",
        "    # ---------------- LLM-BASED EXTRACTION (OPTIONAL) ----------------\n",
        "    def llm_synonym_extract(self, text: str):\n",
        "        prompt = f\"\"\"\n",
        "Extract key symptoms and medical concepts from this patient message.\n",
        "Return JSON ONLY, mapping concept name to:\n",
        "{{\n",
        "  \"Canonical\": \"...\",\n",
        "  \"Original\": \"...\",\n",
        "  \"Synonyms\": [\"...\", \"...\"]\n",
        "}}\n",
        "Message: \"{text}\"\n",
        "\"\"\"\n",
        "        try:\n",
        "            raw = self.llm.invoke(prompt).content.strip()\n",
        "            data = parse_llm_output(raw)\n",
        "            for k, v in data.items():\n",
        "                self.extracted_info[k] = v\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def extract_info_from_text(self, text: str):\n",
        "        self.rule_based_extract(text)\n",
        "        self.llm_synonym_extract(text)\n",
        "\n",
        "    # ---------------- LLM CONDITION GUESS (FALLBACK) ----------------\n",
        "    def llm_condition_guess(self, text: str) -> str | None:\n",
        "        prompt = f\"\"\"\n",
        "Classify the main condition mentioned in this message into ONE of:\n",
        "[\"diabetes\", \"hypertension\", \"heart_disease\", \"copd\", \"none\"].\n",
        "\n",
        "Return JSON like:\n",
        "{{\"condition\": \"...\"}}\n",
        "\n",
        "Message: \"{text}\"\n",
        "\"\"\"\n",
        "        try:\n",
        "            raw = self.llm.invoke(prompt).content.strip()\n",
        "            parsed = json.loads(raw)\n",
        "            cond = parsed.get(\"condition\", \"none\")\n",
        "            if cond in [\"diabetes\", \"hypertension\", \"heart_disease\", \"copd\"]:\n",
        "                return cond\n",
        "        except Exception:\n",
        "            return None\n",
        "        return None\n",
        "\n",
        "    # ---------------- DISAMBIGUATION Q (HEART vs COPD) ----------------\n",
        "    def get_disambiguation_question(self) -> str:\n",
        "        return (\n",
        "            \"Your symptoms could be related to your heart or to a chronic lung condition.\\n\\n\"\n",
        "            \"Please answer in your own words, or choose one option:\\n\\n\"\n",
        "            \"A) I feel abnormal heart activity such as electric pumping, weird or fast heart beats, \"\n",
        "            \"or a tight band feeling in my upper chest, but I do NOT have heavy mucus or phlegm.\\n\\n\"\n",
        "            \"B) I have a long-lasting cough with thick or heavy mucus or phlegm, especially when I smoke, \"\n",
        "            \"or when I am around dust, fumes, or pollution.\"\n",
        "        )\n",
        "\n",
        "    def handle_disambiguation_answer(self, answer: str) -> str | None:\n",
        "        lower = answer.lower()\n",
        "\n",
        "        heart_indicators = [\n",
        "            \"electric pump\",\n",
        "            \"electric pumping\",\n",
        "            \"weird heart beat\",\n",
        "            \"weird heartbeat\",\n",
        "            \"fast heart beat\",\n",
        "            \"fast heartbeat\",\n",
        "            \"irregular heart beat\",\n",
        "            \"irregular heartbeat\",\n",
        "            \"palpitations\",\n",
        "            \"tight band\",\n",
        "        ]\n",
        "        copd_indicators = [\n",
        "            \"heavy mucus\",\n",
        "            \"thick mucus\",\n",
        "            \"a lot of mucus\",\n",
        "            \"phlegm\",\n",
        "            \"cough with mucus\",\n",
        "            \"coughing mucus\",\n",
        "        ]\n",
        "\n",
        "        heart_hit = any(t in lower for t in heart_indicators)\n",
        "        copd_hit = any(t in lower for t in copd_indicators)\n",
        "\n",
        "        if heart_hit and not copd_hit:\n",
        "            return \"heart_disease\"\n",
        "        if copd_hit and not heart_hit:\n",
        "            return \"copd\"\n",
        "\n",
        "        # A/B direct choice\n",
        "        if re.search(r\"\\b(a)\\b\", lower) and not re.search(r\"\\b(b)\\b\", lower):\n",
        "            return \"heart_disease\"\n",
        "        if re.search(r\"\\b(b)\\b\", lower) and not re.search(r\"\\b(a)\\b\", lower):\n",
        "            return \"copd\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    # ---------------- CONDITION IDENTIFICATION ----------------\n",
        "    def identify_condition(self, text: str) -> str | None:\n",
        "        lower = text.lower()\n",
        "\n",
        "        # diabetes\n",
        "        if contains_root(lower, [\"diabet\", \"glucose\", \"blood sugar\"]):\n",
        "            return \"diabetes\"\n",
        "\n",
        "        # hypertension\n",
        "        if contains_root(lower, [\"blood pressure\", \"hypertens\", \"bp\"]):\n",
        "            return \"hypertension\"\n",
        "\n",
        "        # heart disease\n",
        "        has_heart = contains_root(\n",
        "            lower,\n",
        "            [\n",
        "                \"heart\",\n",
        "                \"cardiac\",\n",
        "                \"chest pain\",\n",
        "                \"chest tightness\",\n",
        "                \"angina\",\n",
        "                \"pain when walking\",\n",
        "                \"pain when exercising\",\n",
        "                \"shortness of breath on activity\",\n",
        "                \"heart rate\",\n",
        "                \"palpitations\",\n",
        "                \"fatigue on exertion\",\n",
        "                \"electric pumping\",\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        # copd\n",
        "        has_copd_core = contains_root(\n",
        "            lower, [\"copd\", \"chronic obstructive\", \"emphysema\", \"chronic bronchitis\"]\n",
        "        )\n",
        "        has_copd_symptoms = contains_root(lower, [\"breath\"]) and contains_root(\n",
        "            lower, [\"mucus\", \"phlegm\", \"sputum\"]\n",
        "        )\n",
        "        smoking_and_breath = contains_root(lower, [\"smok\", \"cigarette\"]) and contains_root(\n",
        "            lower, [\"breath\", \"gasp\", \"out of breath\", \"short of breath\"]\n",
        "        )\n",
        "        has_copd = has_copd_core or has_copd_symptoms or smoking_and_breath\n",
        "\n",
        "        # ambiguous heart vs COPD\n",
        "        if has_heart and has_copd:\n",
        "            self.awaiting_disambiguation = True\n",
        "            self.possible_conditions = [\"heart_disease\", \"copd\"]\n",
        "            return None\n",
        "\n",
        "        # unambiguous\n",
        "        if has_heart:\n",
        "            return \"heart_disease\"\n",
        "        if has_copd:\n",
        "            return \"copd\"\n",
        "\n",
        "        # fallback: let LLM guess\n",
        "        return self.llm_condition_guess(text)\n",
        "\n",
        "    # ---------------- QUESTION SKIPPING ----------------\n",
        "    def should_skip_question(self, question: str) -> bool:\n",
        "        q = question.lower()\n",
        "        if \"blood sugar\" in q and \"glucose\" in self.extracted_info:\n",
        "            return True\n",
        "        if \"blood pressure\" in q and \"blood_pressure\" in self.extracted_info:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def get_next_question(self) -> str | None:\n",
        "        \"\"\"\n",
        "        Return the NEXT question to ask without marking interview_complete.\n",
        "        If there are no more questions, returns None.\n",
        "        \"\"\"\n",
        "        if not self.condition_type:\n",
        "            return None\n",
        "\n",
        "        qs = MEDICAL_QUESTIONS.get(self.condition_type, [])\n",
        "\n",
        "        while self.current_question_index < len(qs):\n",
        "            q = qs[self.current_question_index]\n",
        "            if self.should_skip_question(q):\n",
        "                self.current_question_index += 1\n",
        "                continue\n",
        "            return q\n",
        "\n",
        "        # All questions exhausted\n",
        "        return None\n",
        "\n",
        "    # ---------------- INTERVIEW FLOW ----------------\n",
        "    def start_interview(self, initial_message: str) -> str:\n",
        "        \"\"\"\n",
        "        Called once at the beginning with the free-text symptom description.\n",
        "        \"\"\"\n",
        "        self.reset()\n",
        "        self.full_conversation.append(f\"Patient: {initial_message}\")\n",
        "        self.extract_info_from_text(initial_message)\n",
        "        cond = self.identify_condition(initial_message)\n",
        "        self.condition_type = cond\n",
        "\n",
        "        # ambiguous heart vs COPD\n",
        "        if self.awaiting_disambiguation and self.possible_conditions == [\n",
        "            \"heart_disease\",\n",
        "            \"copd\",\n",
        "        ]:\n",
        "            question = self.get_disambiguation_question()\n",
        "            self.full_conversation.append(f\"Agent: {question}\")\n",
        "            return question\n",
        "\n",
        "        # unsupported\n",
        "        if not self.condition_type:\n",
        "            self.interview_complete = True\n",
        "            msg = (\n",
        "                \"Sorry, I can only assist with diabetes, hypertension, \"\n",
        "                \"heart disease, or COPD.\"\n",
        "            )\n",
        "            self.full_conversation.append(f\"Agent: {msg}\")\n",
        "            return msg\n",
        "\n",
        "        # normal flow – first structured question\n",
        "        self.current_question_index = 0\n",
        "        first_q = self.get_next_question()\n",
        "\n",
        "        if first_q is None:\n",
        "            # no structured questions (edge case)\n",
        "            self.interview_complete = True\n",
        "            closing = \"Thank you. I’ve collected your symptoms and will analyze them now.\"\n",
        "            self.full_conversation.append(f\"Agent: {closing}\")\n",
        "            return closing\n",
        "\n",
        "        self.full_conversation.append(f\"Agent: {first_q}\")\n",
        "        return first_q\n",
        "\n",
        "    def continue_interview(self, patient_response: str) -> str:\n",
        "        \"\"\"\n",
        "        Called after each answer. Returns next question or closing message.\n",
        "        \"\"\"\n",
        "        # If we were disambiguating heart vs COPD\n",
        "        if self.awaiting_disambiguation and self.possible_conditions == [\n",
        "            \"heart_disease\",\n",
        "            \"copd\",\n",
        "        ]:\n",
        "            self.full_conversation.append(f\"Patient: {patient_response}\")\n",
        "            self.extract_info_from_text(patient_response)\n",
        "\n",
        "            chosen = self.handle_disambiguation_answer(patient_response)\n",
        "            if not chosen:\n",
        "                guess = self.llm_condition_guess(patient_response)\n",
        "                if guess in [\"heart_disease\", \"copd\"]:\n",
        "                    chosen = guess\n",
        "                else:\n",
        "                    chosen = \"heart_disease\"\n",
        "\n",
        "            self.condition_type = chosen\n",
        "            self.awaiting_disambiguation = False\n",
        "            self.current_question_index = 0\n",
        "\n",
        "            next_q = self.get_next_question()\n",
        "            if next_q is None:\n",
        "                self.interview_complete = True\n",
        "                closing = \"Thank you. I’ve collected your answers and will analyze them now.\"\n",
        "                self.full_conversation.append(f\"Agent: {closing}\")\n",
        "                return closing\n",
        "\n",
        "            self.full_conversation.append(f\"Agent: {next_q}\")\n",
        "            return next_q\n",
        "\n",
        "        # Normal QA flow\n",
        "        self.full_conversation.append(f\"Patient: {patient_response}\")\n",
        "        self.extract_info_from_text(patient_response)\n",
        "\n",
        "        if self.condition_type:\n",
        "            qs = MEDICAL_QUESTIONS.get(self.condition_type, [])\n",
        "            if 0 <= self.current_question_index < len(qs):\n",
        "                prev_q = qs[self.current_question_index]\n",
        "                self.answers[prev_q] = patient_response\n",
        "\n",
        "        # Move index forward and fetch next question\n",
        "        self.current_question_index += 1\n",
        "        next_q = self.get_next_question()\n",
        "\n",
        "        if next_q is None:\n",
        "            # no more questions → now we really finish\n",
        "            self.interview_complete = True\n",
        "            closing = \"Thank you. I’ve collected your answers and will analyze them now.\"\n",
        "            self.full_conversation.append(f\"Agent: {closing}\")\n",
        "            return closing\n",
        "\n",
        "        self.full_conversation.append(f\"Agent: {next_q}\")\n",
        "        return next_q\n",
        "\n",
        "    # ---------------- EXPORT DATA ----------------\n",
        "    def get_collected_data(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"condition_type\": self.condition_type,\n",
        "            \"interview_complete\": self.interview_complete,\n",
        "            \"qa_data\": {**self.answers, **self.extracted_info},\n",
        "            \"full_conversation\": self.full_conversation,\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AnalysisAgent\n",
        "# ============================================================\n",
        "class AnalysisAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def _estimate_severity_llm(self, qa_data: Dict) -> str:\n",
        "        data = qa_data.get(\"qa_data\", {})\n",
        "        full_conv = qa_data.get(\"full_conversation\", [])\n",
        "        red_flag_present = \"red_flag\" in data\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a medical triage assistant (not a doctor).\n",
        "Classify the OVERALL severity into one of:\n",
        "CRITICAL, HIGH, MODERATE, LOW.\n",
        "\n",
        "Return ONLY JSON like:\n",
        "{{\n",
        "  \"severity_label\": \"CRITICAL|HIGH|MODERATE|LOW\",\n",
        "  \"reason\": \"short reason\"\n",
        "}}\n",
        "\n",
        "Condition type: {qa_data.get(\"condition_type\", \"unknown\")}\n",
        "\n",
        "Conversation:\n",
        "{chr(10).join(full_conv)}\n",
        "\n",
        "Collected data:\n",
        "{json.dumps(data, indent=2)}\n",
        "\"\"\"\n",
        "        try:\n",
        "            raw = self.llm.invoke(prompt).content.strip()\n",
        "            parsed = json.loads(raw)\n",
        "            label = str(parsed.get(\"severity_label\", \"\")).upper().strip()\n",
        "        except Exception:\n",
        "            label = \"MODERATE\"\n",
        "\n",
        "        allowed = {\"CRITICAL\", \"HIGH\", \"MODERATE\", \"LOW\"}\n",
        "        if label not in allowed:\n",
        "            label = \"MODERATE\"\n",
        "\n",
        "        if red_flag_present and label in {\"LOW\", \"MODERATE\"}:\n",
        "            label = \"CRITICAL\"\n",
        "\n",
        "        return label\n",
        "\n",
        "    def analyze(self, qa_data: Dict) -> str:\n",
        "        severity = self._estimate_severity_llm(qa_data)\n",
        "\n",
        "        cond_key = qa_data.get(\"condition_type\", \"unknown\")\n",
        "        condition_name_map = {\n",
        "            \"copd\": \"Chronic Obstructive Pulmonary Disease (COPD)\",\n",
        "            \"diabetes\": \"Diabetes\",\n",
        "            \"hypertension\": \"Hypertension\",\n",
        "            \"heart_disease\": \"Heart Disease\",\n",
        "        }\n",
        "        condition_name = condition_name_map.get(cond_key, cond_key)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a medical triage summarizer for a symptom-checking AI.\n",
        "You are NOT a doctor and cannot diagnose, but you can summarize and triage.\n",
        "\n",
        "Use this condition and severity:\n",
        "\n",
        "CONDITION NAME: {condition_name}\n",
        "SEVERITY: {severity}\n",
        "\n",
        "Conversation:\n",
        "{chr(10).join(qa_data.get(\"full_conversation\", []))}\n",
        "\n",
        "Collected QA data:\n",
        "{json.dumps(qa_data.get(\"qa_data\", {}), indent=2)}\n",
        "\n",
        "TASK:\n",
        "Write a brief analysis with these sections:\n",
        "\n",
        "0. *CONDITION NAME:* (use exactly: {condition_name})\n",
        "1. *SEVERITY:* (use exactly: {severity})\n",
        "2. *KEY FINDINGS:* 2–4 bullet points. Mention red flags if present or say 'No red flags reported'.\n",
        "3. *MEDICATION:* Comment if they seem adherent/non-adherent, or say 'Not enough information'.\n",
        "4. *URGENCY:* Suggest timeframe: 'Immediate emergency care', 'Within 24 hours', 'Within a few days', or 'Routine follow-up'.\n",
        "5. *RECOMMENDATIONS:* 3–4 short, practical suggestions (self-monitoring, lifestyle, when to seek urgent help).\n",
        "   Always remind that this is NOT a diagnosis and they must see a real doctor.\n",
        "\n",
        "Be concise and non-alarming. Do NOT change CONDITION NAME or SEVERITY label.\n",
        "\"\"\"\n",
        "        return self.llm.invoke(prompt).content\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PlanningAgent – care plan\n",
        "# ============================================================\n",
        "class PlanningAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def plan(self, analysis_text: str, qa_data: Dict[str, Any]) -> str:\n",
        "        prompt = f\"\"\"\n",
        "You are a planning assistant working with a triage summary.\n",
        "\n",
        "Based on the following analysis and the collected QA data,\n",
        "create a short, structured care plan with these headings:\n",
        "\n",
        "1. Immediate Self-Care Steps\n",
        "2. Short-Term Follow-Up (next days/weeks)\n",
        "3. Questions to Ask the Doctor\n",
        "4. Safety Net (when to seek urgent/emergency care)\n",
        "\n",
        "Keep it concise and patient-friendly.\n",
        "\n",
        "ANALYSIS:\n",
        "{analysis_text}\n",
        "\n",
        "QA DATA:\n",
        "{json.dumps(qa_data.get(\"qa_data\", {}), indent=2)}\n",
        "\"\"\"\n",
        "        return self.llm.invoke(prompt).content\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CoordinatorAgent – runs analysis + planning\n",
        "# ============================================================\n",
        "class CoordinatorAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.analysis_agent = AnalysisAgent(llm)\n",
        "        self.planning_agent = PlanningAgent(llm)\n",
        "\n",
        "    def run_full_pipeline(self, qa_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        analysis_text = self.analysis_agent.analyze(qa_data)\n",
        "        plan_text = self.planning_agent.plan(analysis_text, qa_data)\n",
        "\n",
        "        return {\n",
        "            \"condition_type\": qa_data.get(\"condition_type\"),\n",
        "            \"analysis\": analysis_text,\n",
        "            \"plan\": plan_text,\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MedTwinUserInterface – orchestrates QA + Coordinator\n",
        "# ============================================================\n",
        "class MedTwinUserInterface:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.qaagent = SymptomQAAgent(llm)\n",
        "        self.coordinator = CoordinatorAgent(llm)\n",
        "\n",
        "        self.current_question: str | None = None\n",
        "        self.finished: bool = False\n",
        "        self.qa_data: Dict[str, Any] | None = None\n",
        "\n",
        "    def start_interview(self, initial_problem: str) -> str:\n",
        "        \"\"\"Reset and start a new interview.\"\"\"\n",
        "        self.qaagent = SymptomQAAgent(self.llm)\n",
        "        first_q = self.qaagent.start_interview(initial_problem)\n",
        "        self.current_question = first_q\n",
        "        self.qa_data = None\n",
        "\n",
        "        # If agent immediately says \"sorry, unsupported\", end whole flow\n",
        "        if self.qaagent.interview_complete and self.qaagent.condition_type is None:\n",
        "            self.finished = True  # no Q&A, no analysis, no EHR\n",
        "        else:\n",
        "            self.finished = False\n",
        "\n",
        "        return first_q\n",
        "\n",
        "    def next_question(self, user_answer: str) -> str:\n",
        "        \"\"\"Pass answer to QA agent and get next question (or closing).\"\"\"\n",
        "        next_q = self.qaagent.continue_interview(user_answer)\n",
        "        self.current_question = next_q\n",
        "\n",
        "        if self.qaagent.interview_complete:\n",
        "            self.finished = True\n",
        "            self.qa_data = self.qaagent.get_collected_data()\n",
        "\n",
        "        return next_q\n",
        "\n",
        "    def get_final_report(self) -> Dict[str, Any] | None:\n",
        "        if not self.finished or not self.qa_data:\n",
        "            return None\n",
        "        return self.coordinator.run_full_pipeline(self.qa_data)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EHR TEMPLATE HELPERS (Template 3)\n",
        "# ============================================================\n",
        "def extract_severity_from_analysis(analysis: str) -> str:\n",
        "    \"\"\"\n",
        "    Try to extract the SEVERITY label from the analysis text.\n",
        "    Falls back to 'UNKNOWN' if not found.\n",
        "    \"\"\"\n",
        "    if not analysis:\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "    # Example pattern in analysis: 1. *SEVERITY:* CRITICAL\n",
        "    m = re.search(r\"\\*SEVERITY:\\*\\s*([A-Z]+)\", analysis)\n",
        "    if m:\n",
        "        return m.group(1).strip().upper()\n",
        "\n",
        "    m2 = re.search(r\"SEVERITY[:\\-]\\s*([A-Za-z ]+)\", analysis)\n",
        "    if m2:\n",
        "        return m2.group(1).strip().upper()\n",
        "\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "\n",
        "def build_ehr_summary(report: Dict[str, Any], chat_log: List[tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Build an EHR-style summary using Template 3 (compact summary sheet),\n",
        "    WITHOUT including the detailed care plan.\n",
        "    \"\"\"\n",
        "    analysis = (report.get(\"analysis\") or \"\").strip()\n",
        "    cond_key = (report.get(\"condition_type\") or \"unknown\").lower()\n",
        "\n",
        "    condition_name_map = {\n",
        "        \"copd\": \"Chronic Obstructive Pulmonary Disease (COPD)\",\n",
        "        \"diabetes\": \"Diabetes\",\n",
        "        \"hypertension\": \"Hypertension\",\n",
        "        \"heart_disease\": \"Heart Disease\",\n",
        "        \"unknown\": \"Unknown\",\n",
        "    }\n",
        "    condition_name = condition_name_map.get(cond_key, cond_key.title())\n",
        "\n",
        "    severity = extract_severity_from_analysis(analysis)\n",
        "\n",
        "    # First user message in chat_log = main complaint\n",
        "    main_complaint = \"Not clearly described.\"\n",
        "    for role, text in chat_log:\n",
        "        if role.lower() == \"you\":\n",
        "            main_complaint = text.strip()\n",
        "            break\n",
        "\n",
        "    ehr_text = f\"\"\"========================================\n",
        "EHR SUMMARY SHEET\n",
        "========================================\n",
        "\n",
        "PATIENT SUMMARY\n",
        "----------------------------------------\n",
        "Condition (suspected):   {condition_name}\n",
        "Severity:                {severity}\n",
        "Encounter mode:          Remote symptom interview\n",
        "\n",
        "CLINICAL SNAPSHOT\n",
        "----------------------------------------\n",
        "Main complaint:\n",
        "- {main_complaint}\n",
        "\n",
        "Key findings:\n",
        "{analysis}\n",
        "\n",
        "NOTES\n",
        "----------------------------------------\n",
        "- Detailed care plan is shown separately in the main report.\n",
        "- This summary is generated from a symptom interview.\n",
        "- It is AI-generated and is NOT a medical diagnosis.\n",
        "- A licensed clinician must review and confirm any decisions.\n",
        "\"\"\"\n",
        "    return ehr_text\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STREAMLIT UI\n",
        "# ============================================================\n",
        "st.set_page_config(page_title=\"MedTwin – Symptom Q&A\", page_icon=\"🏥\")\n",
        "\n",
        "st.title(\"🏥 MedTwin – Symptom Q&A & Planning\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "This demo collects information about chronic conditions (Diabetes, Hypertension, Heart Disease, COPD)\n",
        "and generates a triage-style **analysis** and **care plan**.\n",
        "\n",
        "> ⚠️ This does **NOT** provide diagnosis or replace a real doctor.\n",
        "> For emergencies, seek urgent medical care immediately.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "def reset_interview():\n",
        "    st.session_state.system = MedTwinUserInterface(st.session_state.llm)\n",
        "    for key in [\"current_q\", \"chat_log\", \"ehr_decision\", \"report\", \"answer_box\"]:\n",
        "        if key in st.session_state:\n",
        "            del st.session_state[key]\n",
        "    try:\n",
        "        st.rerun()\n",
        "    except Exception:\n",
        "        st.experimental_rerun()\n",
        "\n",
        "\n",
        "# ---------- init session ----------\n",
        "if \"llm\" not in st.session_state:\n",
        "    st.session_state.llm = ChatOllama(model=\"llama3.2:3b\", temperature=0.3)\n",
        "\n",
        "if \"system\" not in st.session_state:\n",
        "    st.session_state.system = MedTwinUserInterface(st.session_state.llm)\n",
        "\n",
        "system: MedTwinUserInterface = st.session_state.system\n",
        "\n",
        "if \"chat_log\" not in st.session_state:\n",
        "    st.session_state.chat_log: List[tuple[str, str]] = []\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Step 1 – Initial symptom description\n",
        "# -------------------------------------------\n",
        "initial_problem = st.text_area(\n",
        "    \"Describe your symptoms in your own words:\",\n",
        "    height=120,\n",
        "    placeholder=\"Example: I quit smoking five years ago, but now I get short of breath when walking...\",\n",
        ")\n",
        "\n",
        "if st.button(\"Start Interview\"):\n",
        "    if initial_problem.strip():\n",
        "        first_q = system.start_interview(initial_problem)\n",
        "        st.session_state.chat_log = [(\"You\", initial_problem), (\"Agent\", first_q)]\n",
        "        st.session_state.current_q = first_q\n",
        "        if \"ehr_decision\" in st.session_state:\n",
        "            del st.session_state[\"ehr_decision\"]\n",
        "        if \"report\" in st.session_state:\n",
        "            del st.session_state[\"report\"]\n",
        "    else:\n",
        "        st.warning(\"Please type your symptoms first.\")\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Step 2 – Q&A loop (only if supported condition)\n",
        "# -------------------------------------------\n",
        "if \"current_q\" in st.session_state and not system.finished:\n",
        "    st.subheader(\"Interview\")\n",
        "\n",
        "    for role, text in st.session_state.chat_log:\n",
        "        st.markdown(f\"**{role}:** {text}\")\n",
        "\n",
        "    user_answer = st.text_input(\"Your answer:\", key=\"answer_box\")\n",
        "\n",
        "    if st.button(\"Send Answer\"):\n",
        "        if user_answer.strip():\n",
        "            bot_reply = system.next_question(user_answer)\n",
        "            st.session_state.chat_log.append((\"You\", user_answer))\n",
        "            st.session_state.chat_log.append((\"Agent\", bot_reply))\n",
        "            st.session_state.current_q = bot_reply\n",
        "        else:\n",
        "            st.warning(\"Please type an answer before sending.\")\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# Step 3 – If finished: either unsupported OR full pipeline\n",
        "# -------------------------------------------\n",
        "if system.finished:\n",
        "    # CASE 1 – unsupported condition (no qa_data)\n",
        "    if system.qa_data is None:\n",
        "        st.subheader(\"Interview ended\")\n",
        "\n",
        "        for role, text in st.session_state.chat_log:\n",
        "            st.markdown(f\"**{role}:** {text}\")\n",
        "\n",
        "        st.info(\n",
        "            \"These symptoms are outside the 4 supported conditions \"\n",
        "            \"(diabetes, hypertension, heart disease, COPD). \"\n",
        "            \"Please consult a real doctor or start a new interview \"\n",
        "            \"for one of the supported conditions.\"\n",
        "        )\n",
        "\n",
        "        if st.button(\"🔁 Start New Interview\"):\n",
        "            reset_interview()\n",
        "\n",
        "    # CASE 2 – normal pipeline with analysis + plan + EHR\n",
        "    else:\n",
        "        if \"report\" not in st.session_state:\n",
        "            st.session_state.report = system.get_final_report()\n",
        "\n",
        "        report = st.session_state.report\n",
        "\n",
        "        if report:\n",
        "            st.subheader(\"Analysis\")\n",
        "            st.markdown(report[\"analysis\"])\n",
        "\n",
        "            st.subheader(\"Care Plan\")\n",
        "            st.markdown(report[\"plan\"])\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\n",
        "                \"Would you like to view this as a structured **EHR-style clinical report**?\"\n",
        "            )\n",
        "\n",
        "            if \"ehr_decision\" not in st.session_state:\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    if st.button(\"Yes, show my EHR report\"):\n",
        "                        st.session_state.ehr_decision = \"yes\"\n",
        "                with col2:\n",
        "                    if st.button(\"No, end interview\"):\n",
        "                        st.session_state.ehr_decision = \"no\"\n",
        "\n",
        "            if st.session_state.get(\"ehr_decision\") == \"no\":\n",
        "                st.success(\"Thank you for using MedTwin. Stay safe.\")\n",
        "                if st.button(\"🔁 Start New Interview\"):\n",
        "                    reset_interview()\n",
        "\n",
        "            if st.session_state.get(\"ehr_decision\") == \"yes\":\n",
        "                ehr_text = build_ehr_summary(report, st.session_state.chat_log)\n",
        "\n",
        "                st.subheader(\"📄 EHR-style Clinical Report (Summary Sheet)\")\n",
        "                st.markdown(f\"```text\\n{ehr_text}\\n```\")\n",
        "\n",
        "                if st.button(\"🔁 Start New Interview\"):\n",
        "                    reset_interview()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill $(lsof -t -i:8501) 2> /dev/null\n",
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 >/dev/null 2>&1 &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBi0Gpv54Oa7",
        "outputId": "ff29c035-98c5-48fa-9c80-05acc9f4f75b"
      },
      "id": "KBi0Gpv54Oa7",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-17T23:20:45+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-429e423b-c646-4aa7-bd63-513fbae04860 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "public_url\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ej6JVjm4QyA",
        "outputId": "4bfb1b1d-8d73-4a71-dc06-442436b81ede"
      },
      "id": "1ej6JVjm4QyA",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://uncatastrophically-unobliterated-mario.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}